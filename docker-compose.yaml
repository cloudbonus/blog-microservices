services:
  postgres:
    container_name: postgres
    image: postgres:16.3
    restart: unless-stopped
    env_file:
      - ./.env
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./configs/postgres:/docker-entrypoint-initdb.d
    environment:
      - POSTGRES_MULTIPLE_DATABASES=blog, epay, keycloak
      - POSTGRES_USER=$POSTGRES_USER
      - POSTGRES_PASSWORD=$POSTGRES_PASSWORD
    ports:
      - ${POSTGRES_LOCAL_PORT}:${POSTGRES_DOCKER_PORT}
    networks:
      - network

  keycloak:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:26.0
    command: [ "start", "--import-realm" ]
    environment:
      KC_HOSTNAME: localhost
      KC_HOSTNAME_PORT: 9090
      KC_HOSTNAME_STRICT_BACKCHANNEL: false
      KC_HTTP_ENABLED: true
      KC_HOSTNAME_STRICT_HTTPS: false
      KC_HEALTH_ENABLED: true
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres/keycloak
      KC_DB_USERNAME: ${POSTGRES_USER}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD}
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports:
      - "9090:8080"
    volumes:
      - ./configs/realms/:/opt/keycloak/data/import/
    depends_on:
      - postgres
    networks:
      - network

#  elasticsearch:
#    image: elasticsearch:8.15.1
#    restart: unless-stopped
#    container_name: elasticsearch
#    env_file:
#      - ./.env
#    environment:
#      - xpack.security.enabled=false
#      - bootstrap.memory_lock=true
#      - "ES_JAVA_OPTS=-Xmx256m -Xms256m"
#      - discovery.type=single-node
#    ports:
#      - ${ELASTIC_LOCAL_PORT}:${ELASTIC_DOCKER_PORT}
#    networks:
#      - network
#
#  logstash:
#    image: logstash:8.15.1
#    restart: unless-stopped
#    container_name: logstash
#    env_file:
#      - ./.env
#    volumes:
#      - ./configs/logstash/pipeline:/usr/share/logstash/pipeline:ro
#    environment:
#      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
#    ports:
#      - ${LOGSTASH_LOCAL_PORT}:${LOGSTASH_DOCKER_PORT}
#    networks:
#      - network
#
#  kibana:
#    image: kibana:8.15.1
#    container_name: kibana
#    environment:
#      - ELASTICSEARCH_HOSTS=${ELASTIC_HOST}
#    ports:
#      - ${KIBANA_LOCAL_PORT}:${KIBANA_DOCKER_PORT}
#    networks:
#      - network
#
#  redis:
#    image: redis:7.4.0
#    restart: unless-stopped
#    container_name: redis
#    env_file:
#      - ./.env
#    ports:
#      - ${REDIS_LOCAL_PORT}:${REDIS_DOCKER_PORT}
#    networks:
#      - network
#
#  epay:
#    container_name: epay
#    depends_on:
#      - postgres
#    build:
#      context: epay
#      dockerfile: ./Dockerfile
#    restart: on-failure
#    env_file:
#      - ./.env
#    environment:
#      - SPRING_DATASOURCE_URL=$EPAY_DATASOURCE_URL
#      - SPRING_DATASOURCE_USERNAME=$POSTGRES_USER
#      - SPRING_DATASOURCE_PASSWORD=$POSTGRES_PASSWORD
#      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
#    ports:
#      - ${EPAY_LOCAL_PORT}:${EPAY_DOCKER_PORT}
#    networks:
#      - network
#
#  blog:
#    container_name: blog
#    depends_on:
#      - postgres
#      - redis
#    build:
#      context: blog
#      dockerfile: ./Dockerfile
#    restart: on-failure
#    env_file:
#      - ./.env
#    environment:
#      - SPRING_DATASOURCE_URL=$BLOG_DATASOURCE_URL
#      - SPRING_DATASOURCE_USERNAME=$POSTGRES_USER
#      - SPRING_DATASOURCE_PASSWORD=$POSTGRES_PASSWORD
#      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
#    ports:
#      - ${BLOG_LOCAL_PORT}:${BLOG_DOCKER_PORT}
#    networks:
#      - network
#
#  discovery-server:
#    container_name: discovery-server
#    build:
#      context: ./discovery-server
#      dockerfile: ./Dockerfile
#    restart: on-failure
#    ports:
#      - 8761:8761
#    networks:
#      - network
#
#  api-gateway:
#    container_name: api-gateway
#    build:
#      context: ./api-gateway
#      dockerfile: ./Dockerfile
#    restart: on-failure
#    ports:
#      - 8888:8888
#    networks:
#      - network
#
#
#  zookeeper:
#    image: wurstmeister/zookeeper
#    container_name: zookeeper
#    restart: no
#    env_file:
#      - ./.env
#    ports:
#      - ${ZOOKEEPER_LOCAL_PORT}:${ZOOKEEPER_DOCKER_PORT}
#    networks:
#      - network
#
#  kafka:
#    image: wurstmeister/kafka
#    container_name: kafka
#    depends_on:
#      - zookeeper
#    restart: no
#    env_file:
#      - ./.env
#    environment:
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: DOCKER_INTERNAL:PLAINTEXT,DOCKER_EXTERNAL:PLAINTEXT
#      KAFKA_LISTENERS: DOCKER_INTERNAL://:29092,DOCKER_EXTERNAL://:9092
#      KAFKA_ADVERTISED_LISTENERS: DOCKER_INTERNAL://kafka:29092,DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
#      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER_INTERNAL
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:$ZOOKEEPER_DOCKER_PORT
#      KAFKA_BROKER_ID: 1
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#      KAFKA_CREATE_TOPICS: "t.request:1:1,t.update:1:1"
#    ports:
#      - ${KAFKA_LOCAL_PORT}:${KAFKA_DOCKER_PORT}
#    networks:
#      - network

volumes:
  pgdata:

networks:
  network:
    name: network
    driver: bridge